## Chat API + RAG contract (v2)

This doc defines the **public API contract** for chat + artifact generation:
- request/response JSON shapes
- server-driven UI directives
- artifact models (Fit Brief + Relevant Experience)
- share snapshot lifecycle (immutable permalink)

Runtime/infra choices (reverse proxy, hosting, DynamoDB table details) live in:
- `_specs/runtime-architecture.md`

Retrieval storage schema lives in:
- `_specs/qdrant-index-design.md`

---

## Endpoints (MVP)

### 1) `POST /api/chat`
Generates:
- next assistant message
- updated artifacts (Fit Brief + Relevant Experience)
- UI directives (chat vs split)
- UX hints (e.g. suggest which split tab to focus, suggest Share)

Notes:
- **Public endpoint** (UI): `POST /api/chat`
- **Service internal endpoint** (chat-api-service): `POST /chat`
  - In production we route `/api/*` to the service (same-origin) so the UI can call `/api/chat` without CORS.

#### Request

```json
{
  "conversationId": "uuid-v4",
  "client": {
    "origin": "https://your-domain.example.com",
    "page": { "path": "/v2", "referrerShareId": null },
    "ui": {
      "view": "chat",
      "split": { "activeTab": "brief" }
    },
    "thinkingEnabled": true
  },
  "messages": [
    { "role": "user", "text": "..." },
    { "role": "assistant", "text": "..." }
  ]
}
```

Rules:
- The UI sends the last ~8–20 messages (bounded).
- The UI includes the current `client.ui` so the model can be tactful (e.g., don’t keep suggesting the other tab every turn).
- `referrerShareId` is optional and only used for analytics/tone (“came from a shared link”).
- `thinkingEnabled` is optional and defaults to `true`. Details: `_specs/thinking-mode.md`.

#### Response

```json
{
  "assistant": { "text": "..." },
  "usage": {
    "outputTokens": 8452,
    "byAgent": {
      "router": { "outputTokens": 112 },
      "answer": { "outputTokens": 8340 }
    }
  },
  "ui": {
    "view": "split",
    "split": { "activeTab": "brief" }
  },
  "hints": {
    "suggestShare": false,
    "suggestTab": null
  },
  "chips": ["B2B SaaS product", "Consumer fintech", "AI/ML platform"],
  "artifacts": {
    "fitBrief": {
      "title": "Fit brief — Jaan Sokk",
      "sections": [
        { "id": "need", "title": "What I think you need", "content": "..." },
        { "id": "proof", "title": "Where I’ve done this before", "content": "..." }
      ]
    },
    "relevantExperience": {
      "groups": [
        {
          "title": "Most relevant",
          "items": [
            {
              "slug": "guardtime-po",
              "type": "experience",
              "title": "GuardTime",
              "role": "Product Owner",
              "period": "2024–2025",
              "bullets": [
                "..."
              ],
              "whyRelevant": "Optional one-liner"
            }
          ]
        }
      ]
    }
  },
  "thinking": "Optional. Summarized reasoning when thinkingEnabled=true"
}
```

Rules:
- `ui.view` is **server-driven**:
  - `"chat"` = single-column
  - `"split"` = workspace (chat + left tabs)
- `ui.split` is **required when** `ui.view="split"`:
  - `ui.split.activeTab` is `"brief"` or `"experience"` (server recommendation for initial focus)
- `ui.split` is optional/ignored when `ui.view="chat"`.
- `hints.suggestTab` is an **LLM/server suggestion** for which split tab to focus:
  - `"brief"` or `"experience"` means “subtly highlight that tab”
  - `null` means “no suggestion”
  - UI should not auto-switch tabs purely based on this hint (user remains in control).
- `chips[]` are optional (UX acceleration).
- `hints.suggestShare` is optional:
  - `true` means “it may be a good moment to share” (UI can subtly highlight the Share button)
  - it does not open the modal; Share remains user-initiated.
- Artifacts are returned as **rendered state** (not diffs) in MVP.
- `usage` is optional and intended for **latency/cost comparisons** in the UI:
  - `usage.outputTokens` is the server’s best-available count of **LLM output tokens** for this turn, **summed across LLM agents** (currently `router` + `answer`).
  - For Anthropic streaming, `answer.outputTokens` is derived from `message_delta.usage.output_tokens` (cumulative) per Anthropic’s streaming docs.

Implementation notes (current code):
- **Router does not supply chips**: chips are generated by the answer step and must match `assistant.text`.
- **`hints.suggestShare` is currently always `false`** (Share is UI-initiated).
- **Split guard**: the service may downgrade `ui.view` from `"split"` → `"chat"` if it cannot produce renderable artifacts (to avoid an empty workspace).
- Thinking mode details (streaming `event: thinking`, constraints, fallbacks): `_specs/thinking-mode.md`.

---

### 1b) `POST /api/chat/stream` (SSE)
Streaming variant of chat. (Currently Antrhopic only)

Notes:
- **Public endpoint** (UI): `POST /api/chat/stream`
- **Service internal endpoint**: `POST /chat/stream`

The response is **Server-Sent Events** (`text/event-stream`) with:
- `event: ui` (early directive): `data: {"ui": {...}, "hints": {"suggestTab": ...}}`
- `event: thinking` (reasoning deltas, when `thinkingEnabled`): `data: {"delta": "..."}`
- `event: text` (token deltas): `data: {"delta": "..."}`
- `event: done` (final response): `data: {ChatApiResponse}`
- `event: error`: `data: {"error": "..."}`

The final `done` payload must match the `POST /api/chat` response shape.
Thinking mode behavior details: `_specs/thinking-mode.md`.

---

### 2) `POST /api/share`
Creates an **immutable share snapshot** and returns a permalink.

The UI should call this only after the user provides **LinkedIn OR email** in the Share modal.

Notes:
- **Public endpoint** (UI): `POST /api/share`
- **Service internal endpoint**: `POST /share`

#### Request

```json
{
  "createdByContact": "linkedin.com/in/yourprofile-or-email@example.com",
  "snapshot": {
    "conversationId": "uuid-v4",
    "createdAt": "2026-01-06T12:34:56.000Z",
    "ui": {
      "view": "split",
      "split": { "activeTab": "brief" }
    },
    "messages": [
      { "role": "user", "text": "..." },
      { "role": "assistant", "text": "..." }
    ],
    "artifacts": {
      "fitBrief": { "title": "...", "sections": [] },
      "relevantExperience": { "groups": [] }
    }
  }
}
```

Rules:
- Snapshot stores **rendered artifacts only** (no retrieval citations).
- Snapshot `artifacts` must include both:
  - `fitBrief`
  - `relevantExperience`
- The server must validate and sanitize `snapshot`:
  - bound `messages` length
  - validate artifact shapes
  - ensure `ui` values are valid

PDF note (UX requirement):
- The “Download PDF” action should generate a PDF from this same share snapshot, and it must include **Fit Brief + Relevant Experience**.
  - Current UI implementation: **PDF download is not yet enabled** (button is disabled/commented out).

#### Response

```json
{
  "shareId": "opaque-id",
  "path": "/c/opaque-id"
}
```

Rules:
- Share links are guess-resistant opaque IDs.
- Share links **never expire**.

---

### 3) `GET /api/share/{shareId}`
Fetches a previously created share snapshot for rendering `/c/{shareId}`.

Notes:
- **Public endpoint** (UI): `GET /api/share/{shareId}`
- **Service internal endpoint**: `GET /share/{shareId}`

#### Response

```json
{
  "shareId": "opaque-id",
  "createdAt": "2026-01-06T12:34:56.000Z",
  "snapshot": {
    "conversationId": "uuid-v4",
    "ui": { "view": "split", "split": { "activeTab": "brief" } },
    "messages": [],
    "artifacts": {
      "fitBrief": { "title": "...", "sections": [] },
      "relevantExperience": { "groups": [] }
    }
  }
}
```

Rules:
- This is a **read-only snapshot**.
- If the user continues chatting from `/c/{shareId}`, the UI starts a new conversation ID and calls `POST /api/chat`.
- Fork does **not** inherit any captured LinkedIn/email.

---

## Artifact models (normative)

### Fit Brief
`fitBrief.sections[]` is a list of sections. Sections may be omitted if:
- not enough evidence
- not enough confidence

The model must prefer omission over hallucination.

Suggested section IDs (initial template):
- `need` — What I think you need
- `proof` — Where I’ve done this before
- `risks` — Risks I’d watch
- `plan` — First 30/60/90 days
- `questions` — Questions I’d ask in interview

### Relevant Experience
Grouped sections:
- `relevantExperience.groups[]`
  - each group has `title` and `items[]`

Each item:
- references a `slug` and `type` (`experience` or `project`)
- provides 2–4 grounded bullets (metrics/achievements when possible)
- can include an optional `whyRelevant`

---

## RAG behavior (MVP summary)

### Retrieval intent (LLM-assisted)
The service uses an LLM “router” step to produce:
- a retrieval query rewrite
- recommended `ui.view` + `ui.split.activeTab`
- optional `hints` (e.g., `suggestTab`)

### Vector retrieval
- Retrieve candidate chunks from the corpus.
- Use background content for tone/context only; never surface background as “Relevant Experience”.
- Background chunks are capped (defaults: `MAX_BACKGROUND_CHUNKS=2`, `MAX_MAIN_CHUNKS=10`).

### Answer + artifact generation
The model generates:
- `assistant.text`
- `ui` directives
- `artifacts.fitBrief` and `artifacts.relevantExperience`
- `chips[]` (optional)

### Validation / sanitization
The service must validate response JSON and enforce:
- `ui.view` and `activeTab` allowed values
- `relevantExperience` only contains `type in ("experience","project")`
- bounded lengths (messages, bullets, sections) to keep UI stable
- relevantExperience items must be **UI-visible** (validated against Qdrant item metadata: `visibleIn` / `uiVisible`)

---


